{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import joblib\n",
    "import zipfile\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_PATH = \"../../data/raw/\"\n",
    "PROCESSED_DATA_PATH = \"../../data/processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump(value = None, filename = None):\n",
    "    if (value is not None) and (filename is not None):\n",
    "        joblib.dump(value=value, filename=filename)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Value or filename cannot be None\".capitalize())\n",
    "    \n",
    "def load(filename = None):\n",
    "    if filename is not None:\n",
    "        return joblib.load(filename)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Filename cannot be None\".capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader():\n",
    "    def __init__(self, image_path = None, image_size = 64, split_size = 0.20, batch_size = 1):\n",
    "        self.image_path = image_path\n",
    "        self.image_size = image_size\n",
    "        self.split_size = split_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.LR = []\n",
    "        self.HR = []\n",
    "\n",
    "    def split_dataset(self, X = None, y = None):\n",
    "        if isinstance(X, list) and isinstance(y, list):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = self.split_size, random_state=42, shuffle=True)\n",
    "\n",
    "            return {\"X_train\": X_train, \"X_test\": X_test, \"y_train\": y_train, \"y_test\": y_test}\n",
    "\n",
    "    def transforms(self, type = \"lr\"):\n",
    "        if type == \"lr\":\n",
    "            return transforms.Compose([\n",
    "                transforms.Resize((self.image_size, self.image_size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.CenterCrop((self.image_size, self.image_size)),\n",
    "                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "            ])\n",
    "\n",
    "        elif type == \"hr\":\n",
    "            return transforms.Compose([\n",
    "                transforms.Resize((self.image_size*4, self.image_size*4)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.CenterCrop((self.image_size*4, self.image_size*4)),\n",
    "                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "            ])\n",
    "\n",
    "    def unzip_folder(self):\n",
    "        if os.path.exists(RAW_DATA_PATH):\n",
    "            with zipfile.ZipFile(self.image_path, \"r\") as zip_file:\n",
    "                zip_file.extractall(os.path.join(RAW_DATA_PATH))\n",
    "        else:\n",
    "            raise Exception(\"RAW data path is not found\".capitalize())\n",
    "\n",
    "    def feature_extraction(self):\n",
    "\n",
    "        self.directory = os.path.join(RAW_DATA_PATH, \"dataset\")\n",
    "\n",
    "        self.higher_resolution_images = os.path.join(self.directory, \"HR\")\n",
    "        self.low_resolution_images = os.path.join(self.directory, \"LR\")\n",
    "\n",
    "        for image in os.listdir(self.low_resolution_images):\n",
    "            if image in os.listdir(self.higher_resolution_images):\n",
    "                lower_resolution_image_path = os.path.join(self.low_resolution_images, image)\n",
    "                higher_resolution_image_path = os.path.join(self.higher_resolution_images, image)\n",
    "\n",
    "                lower_resolution_image = cv2.imread(lower_resolution_image_path)\n",
    "                higher_resolution_image = cv2.imread(higher_resolution_image_path)\n",
    "\n",
    "                lower_resolution_image = cv2.cvtColor(lower_resolution_image, cv2.COLOR_BGR2RGB)\n",
    "                higher_resolution_image = cv2.cvtColor(higher_resolution_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                lower_resolution_image = Image.fromarray(lower_resolution_image)\n",
    "                higher_resolution_image = Image.fromarray(higher_resolution_image)\n",
    "\n",
    "                self.LR.append(self.transforms(type=\"lr\")(lower_resolution_image))\n",
    "                self.HR.append(self.transforms(type=\"hr\")(higher_resolution_image))\n",
    "\n",
    "        assert len(self.LR) == len(self.HR)\n",
    "\n",
    "        print(\"Total {} images have been captured\".format(len(self.LR)).capitalize())\n",
    "\n",
    "        return self.split_dataset(X=self.LR, y=self.HR)\n",
    "\n",
    "    def create_dataloader(self):\n",
    "        try:\n",
    "            dataset = self.feature_extraction()\n",
    "\n",
    "        except Exception as e:\n",
    "            raise Exception(\"Feature extraction process has been failed\".capitalize())\n",
    "\n",
    "        else:\n",
    "            train_dataloader = DataLoader(\n",
    "                dataset = list(zip(dataset[\"X_train\"], dataset[\"y_train\"])),\n",
    "                batch_size = self.batch_size,\n",
    "                shuffle = True\n",
    "            )\n",
    "            valid_dataloader = DataLoader(\n",
    "                dataset = list(zip(dataset[\"X_test\"], dataset[\"y_test\"])),\n",
    "                batch_size=self.batch_size*8,\n",
    "                shuffle=True\n",
    "            )\n",
    "\n",
    "            for dataloader, filename in [(train_dataloader, \"train_dataloader\"), (valid_dataloader, \"valid_dataloader\")]:\n",
    "                dump(value=dataloader, filename=os.path.join(PROCESSED_DATA_PATH, filename+\".pkl\"))\n",
    "\n",
    "            print(\"train and valid dataloader has been created in the folder : {}\".format(PROCESSED_DATA_PATH).capitalize())\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_images():\n",
    "        dataloader = load(filename=os.path.join(PROCESSED_DATA_PATH, \"valid_dataloader.pkl\"))\n",
    "\n",
    "        data, labels = next(iter(dataloader))\n",
    "\n",
    "        plt.figure(figsize=(20, 10))\n",
    "\n",
    "        for index, image in enumerate(data):\n",
    "            X = image.squeeze().permute(1, 2, 0).detach().cpu().numpy()\n",
    "            y = labels[index].squeeze().permute(1, 2, 0).detach().cpu().numpy()\n",
    "\n",
    "            X = (X - X.min()) / (X.max() - X.min())\n",
    "            y = (y - y.min()) / (y.max() - y.min())\n",
    "\n",
    "            plt.subplot(2 * 2, 2 * 4, 2 * index + 1)\n",
    "            plt.imshow(X)\n",
    "            plt.title(\"LR\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.subplot(2 * 2, 2 * 4, 2 * index + 2)\n",
    "            plt.imshow(y)\n",
    "            plt.title(\"HR\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    loader = Loader(\n",
    "        image_path=\"../../data/raw/dataset.zip\",\n",
    "        image_size=64,\n",
    "        split_size=0.40\n",
    "    )\n",
    "    loader.unzip_folder()\n",
    "    loader.create_dataloader()\n",
    "    \n",
    "    loader.plot_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, in_channels = 64, out_channels = 64):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "    def block(self, in_channels, out_channels):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            raise TypeError(\"Input must be a tensor\".capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPSG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
